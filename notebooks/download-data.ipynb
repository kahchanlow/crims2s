{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcf8afa3-96b0-45f4-93e5-27a86e40928f",
   "metadata": {},
   "source": [
    "# Download Data\n",
    "\n",
    "Download all data provided by the organizers.\n",
    "There are multiple data repositories, according to a nomenclature defined here https://github.com/ecmwf-lab/climetlab-s2s-ai-challenge.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "551c12a8-28bf-43c7-b8f1-afb7758ad839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import multiprocessing\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import requests\n",
    "import urllib\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "INDEX_TRAIN_INPUT = 'https://storage.ecmwf.europeanweather.cloud/s2s-ai-challenge/data/training-input/0.3.0/netcdf/index.html'\n",
    "INDEX_TRAIN_OUTPUT = 'https://storage.ecmwf.europeanweather.cloud/s2s-ai-challenge/data/training-output-benchmark/index.html'\n",
    "#INDEX_TRAIN_REFERENCE = 'https://storage.ecmwf.europeanweather.cloud/s2s-ai-challenge/data/training-output-reference/index.html'\n",
    "\n",
    "INDEX_TEST_INPUT = 'https://storage.ecmwf.europeanweather.cloud/s2s-ai-challenge/data/test-input/0.3.0/netcdf/index.html'\n",
    "INDEX_TEST_OUTPUT = 'https://storage.ecmwf.europeanweather.cloud/s2s-ai-challenge/data/test-output-benchmark/index.html'\n",
    "#INDEX_TEST_REFERENCE = 'https://storage.ecmwf.europeanweather.cloud/s2s-ai-challenge/data/test-output-reference/index.html'\n",
    "#HOME = \"C:\\\\Users\\\\klow55\\\\github\\\\crims2s\"\n",
    "#HOME = \"C:\\\\Users\\\\kahch\\\\src\\\\crims2s\\\\crims2s\"\n",
    "HOME = \"E:\\\\weatherdata\"\n",
    "TARGET_DIR = os.path.join(HOME, 's2s')\n",
    "#os.makedirs(TARGET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02dd07c6-8a00-45be-b1ab-52762c48900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_index(index_url):\n",
    "    html = requests.get(index_url).text\n",
    "    soup = bs4.BeautifulSoup(html, 'html.parser')\n",
    "    try:\n",
    "        table = soup.find_all('tbody')[0]\n",
    "        links = table.find_all('a')\n",
    "        dataset_files = [a_tag.attrs['href'] for a_tag in links]\n",
    "    except Exception as e:\n",
    "        print(f\"{e}: {index_url}\")\n",
    "        dataset_files = []\n",
    "    return dataset_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85be6db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<?xml version=\"1.0\" encoding=\"UTF-8\"?><Error><Code>AccessDenied</Code><BucketName>s2s-ai-challenge</BucketName><RequestId>tx0000000000000000726bd-0062f466b3-2a4cdd6c-default</RequestId><HostId>2a4cdd6c-default-default</HostId></Error>'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_url=INDEX_TRAIN_REFERENCE\n",
    "html = requests.get(index_url).text\n",
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30324369-f4e5-417c-b10a-006ac8c1adbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_one_dataset_file(file_url):\n",
    "    \"\"\"Inspired by https://stackoverflow.com/questions/16694907/download-large-file-in-python-with-requests.\"\"\"\n",
    "    url_path = urllib.parse.urlparse(file_url).path\n",
    "    paths = url_path.split('/')\n",
    "    download_dir = os.path.join(TARGET_DIR, paths[3])\n",
    "    download_path = os.path.join(download_dir, paths[4])\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "    with requests.get(file_url, stream=True) as stream:\n",
    "        if os.path.isfile(download_path):\n",
    "            \"\"\"Ignore file if it already exists and file size is ok.\"\"\"\n",
    "            stream_len = int(stream.headers['Content-length'])\n",
    "            local_len = os.path.getsize(download_path)\n",
    "\n",
    "            if stream_len == local_len:               \n",
    "                return download_path\n",
    "        \n",
    "        \n",
    "        with open(download_path, 'wb') as f:\n",
    "            for chunk in stream.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "                \n",
    "    return download_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad9cfbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3034\n"
     ]
    }
   ],
   "source": [
    "files_to_read = read_index(INDEX_TRAIN_INPUT)\n",
    "print(len(files_to_read))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8df7474-52c0-4b40-9978-766bbfce2b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range: https://storage.ecmwf.europeanweather.cloud/s2s-ai-challenge/data/training-output-reference/index.html\n",
      "list index out of range: https://storage.ecmwf.europeanweather.cloud/s2s-ai-challenge/data/test-output-reference/index.html\n"
     ]
    }
   ],
   "source": [
    "dataset_files = []\n",
    "for index in [INDEX_TRAIN_OUTPUT, INDEX_TRAIN_INPUT, INDEX_TRAIN_REFERENCE, INDEX_TEST_REFERENCE, INDEX_TEST_INPUT, INDEX_TEST_OUTPUT]:\n",
    "#    print(index)\n",
    "    dataset_files.extend(read_index(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35c1929e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3046"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c237c58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://storage.ecmwf.europeanweather.cloud/s2s-ai-challenge/data/training-output-benchmark/t2m-weeks-34.nc'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00ccbcbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training-output-benchmark/t2m-weeks-34.nc'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.parse.urlparse(dataset_files[0]).path[23:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65fa02d3-8f0a-4026-8e5c-b0250b4dba11",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "makedirs() got an unexpected keyword argument 'existing_ok'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdownload_one_dataset_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_files\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36mdownload_one_dataset_file\u001b[1;34m(file_url)\u001b[0m\n\u001b[0;32m      5\u001b[0m download_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(TARGET_DIR, paths[\u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m      6\u001b[0m download_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_dir, paths[\u001b[38;5;241m4\u001b[39m])\n\u001b[1;32m----> 7\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownload_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexisting_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mget(file_url, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m stream:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(download_path):\n",
      "\u001b[1;31mTypeError\u001b[0m: makedirs() got an unexpected keyword argument 'existing_ok'"
     ]
    }
   ],
   "source": [
    "download_one_dataset_file(dataset_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5632031",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"E:\\\\weatherdata\\\\indices\\\\s2sdatafiles.txt\", \"wt\") as fout:\n",
    "    for f in dataset_files:\n",
    "        fout.write(f+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12af71bc-c549-4ce0-9247-7d6542248f2d",
   "metadata": {},
   "source": [
    "## Test local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9059e1-6d82-4f98-8458-71fb21c0d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257e88b6-11d4-419b-b48b-82080f846dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = xr.open_dataset(local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f15ba6-c503-4b13-a090-9c8aca6c6e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1290bb0a-250f-4822-a780-d79174d7d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.lead_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad60401-eb58-4056-a224-2d1621fcd31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.t2m.isel(lead_time=0, forecast_time=2, category=0).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115be162-8634-41a7-a751-4b9257097323",
   "metadata": {},
   "source": [
    "## Batch Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1161fa-d0b0-47f4-9006-d9da0c187e89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.shuffle(dataset_files)\n",
    "\n",
    "with multiprocessing.Pool(processes=16) as pool:\n",
    "    for _ in tqdm(pool.imap(download_one_dataset_file, dataset_files), total=len(dataset_files)):\n",
    "        pass        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e1572b-5e26-4425-bd4b-96b0f79519f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"singles.txt\") as fin:\n",
    "    for line in fin:\n",
    "        downloaded = download_one_dataset_file(line.strip())\n",
    "        print(downloaded)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4187826-8dce-4910-8b1d-a639ee79d1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
